---
weight: 10
---

# Upgrade from AI 1.3


## Before Upgrading

<Steps>
### Keep Inference Service Runtimes
This step ensures that older ClusterServingRuntime resources are not inadvertently removed during the upgrade process. The script adds the `"helm.sh/resource-policy": "keep"` annotation to all `ClusterServingRuntime` resources, which instructs Helm to preserve them during the upgrade.


Execute the following script in the destination cluster:

```bash title="migrate-clusterservingruntime-resources.sh"
#!/bin/bash
set -e

# Check if kubectl is installed
if ! command -v kubectl &> /dev/null; then
    echo "Error: kubectl not found. Please install kubectl and ensure it is in your PATH."
    exit 1
fi

echo "Fetching all ClusterServingRuntime resources and checking for annotations..."

kubectl get clusterservingruntime --no-headers -o name | while read -r name; do

    if kubectl get "$name" -o yaml | grep -q 'helm.sh/resource-policy: keep'; then
        echo "ClusterServingRuntime $name already has the 'helm.sh/resource-policy: keep' annotation. Skipping."
    else
        echo "ClusterServingRuntime $name does not have the 'helm.sh/resource-policy: keep' annotation. Patching..."
        
        kubectl patch "$name" \
            --type=merge \
            -p '{"metadata":{"annotations":{"helm.sh/resource-policy": "keep"}}}'
        
        echo "Successfully patched $name."
    fi
done

echo "migrate-clusterservingruntime-resources completed."

```



### Migrate InferenceService resources

Before **Alauda AI** `1.4`, `InferenceService` resources did not explicitly specify their deployment mode. You must now explicitly define the deployment mode for all your inference services before upgrading.

:::warning
This migration updates your inference services. In **Knative Serverless** mode it triggers a rolling update: a new `revision` is created and the old one is deleted only after the new one is `Ready`.

If the service may be resourceâ€‘constrained (**GPU/CPU/memory**), schedule a maintenance window or temporarily stop the service before running the script.
:::


Execute following script in destination cluster:

```bash title="migrate-inferenceservice-resources.sh"
#!/bin/bash

set -e

kubectl get inferenceservice --all-namespaces -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name --no-headers | while read -r namespace name; do

    if kubectl get inferenceservice "$name" -n "$namespace" -o yaml | grep -q 'serving.kserve.io/deploymentMode:' ; then
        echo "InferenceService ${namespace}/${name} already has 'serving.kserve.io/deploymentMode' annotation. Skipping."
    else
        echo "InferenceService ${namespace}/${name} does not have 'serving.kserve.io/deploymentMode' annotation. Patching..."

        kubectl patch inferenceservice "$name" -n "$namespace" --type=merge -p '{"metadata":{"annotations":{"serving.kserve.io/deploymentMode": "Serverless"}}}'

        echo "Successfully patched ${namespace}/${name}."
    fi
done

echo "migrate-inferenceservice-resources completed."

```
</Steps>

## Install Alauda AI Cluster Components

Please visit [Alauda AI Cluster](../installation/ai-cluster.mdx) for:

:::warning
Please ignore `Creating Alauda AI Cluster Instance` since we are upgrading **Alauda AI** from a previously managed version.
:::

1. [Downloading](../installation/ai-cluster.mdx#downloading) operator bundle packages for `Alauda AI Cluster` and `KServeless`.
2. [Uploading](../installation/ai-cluster.mdx#uploading) operator bundle packages to the destination cluster.
3. To upgrade, follow the process described below.
    
    

## Upgrading

The following procedure describes how to upgrade from **AI** `1.3` to **Alauda AI** `1.4`.

### Upgrading Alauda AI Operators

The procedure for upgrading both operators is nearly identical, with only the target component being different.

| Step | Alauda AI Operator | Alauda AI Model Serving Operator |
| :--- | :--- | :--- |
| **1. Navigate** | Log into the Web Console, then go to **Marketplace > OperatorHub** in the **Administrator** view. | Log into the Web Console, then go to **Marketplace > OperatorHub** in the **Administrator** view. |
| **2. Select** | Select your target **cluster**. | Select your target **cluster**. |
| **3. Click** | Click the **Alauda AI** card. | Click the **Alauda AI Model Serving** card. |
| **4. Confirm** | Click **Confirm** on the upgrade prompt. | Click **Confirm** on the upgrade prompt. |

:::info
    Once the new version is uploaded and recognized by the platform, an upgrade prompt will appear at the top of the operator's page.
:::
## Verification

<Steps>
### Alauda AI
Check the status field from the `AmlCluster` resource which named `default`:

```bash
kubectl get amlcluster default
```

Should returns `Ready`:

```
NAME      READY   REASON
default   True    Succeeded
```
### Alauda AI Model Serving
Check the status field from the `KnativeServing` resource which named `default-knative-serving`:

```bash
kubectl get KnativeServing.components.aml.dev default-knative-serving
```

Should returns `InstallSuccessful`:

```
NAME                      DEPLOYED   REASON
default-knative-serving   True       InstallSuccessful
```
</Steps>