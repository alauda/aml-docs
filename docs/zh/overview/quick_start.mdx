---
weight: 30
sourceSHA: f9e806874104044ad33e93279de8a5fad0720bc79abda380caa94c0faf693af7
---

# 快速开始

本文档旨在帮助新用户快速了解如何在 Alauda AI 中部署推理服务。通过部署一个简单的“文本生成”推理服务并进行体验，您可以快速掌握平台的主要功能和使用方法。

## 介绍

### 适用场景

- 您是 Alauda AI 的新用户，希望快速了解如何将模型发布为可调用的推理服务。
- 您希望通过一个简单的示例了解 Alauda AI 的基本功能，包括上传模型、发布推理服务和调用推理服务。
- 您刚刚部署了一个新的 Alauda AI 环境，想要快速验证其是否可用。

### 预计阅读时间

预计完成本文档的阅读和操作时间约为 20 分钟。

## 注意事项

本文档仅演示基本流程。如需详细的参数配置，请参考完整文档。

## 前提条件

- 您已经拥有一个平台管理员账户（用于创建和管理命名空间）。
- 您已准备好要部署的模型文件（可以从 Hugging Face 或 ModelScope 等网站提前下载）。
- 如果需要使用 GPU 推理，请确保已安装 GPU 插件；如未安装，请在平台管理插件中心安装 GPU 插件。
- 您了解 Kubernetes 和机器学习模型的基本概念。

## 流程概述

| 序号 | 操作步骤                | 描述                                                                                             | 注意事项                                                                                 |
| ---- | ----------------------- | ------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------- |
| 1    | 创建命名空间            | 在容器平台中创建命名空间，并为用户配置相关的 Alauda AI 权限                                   | 如果您已经有命名空间且已分配用户权限，请跳过此步骤                                      |
| 2    | 管理命名空间            | 将命名空间纳入 Alauda AI 管理                                                                    | 如果命名空间已经被管理，请跳过此步骤                                                   |
| 3    | 上传模型                | 将模型文件上传到模型库                                                                          | 如果您已上传模型或使用的是平台共享模型，请跳过此步骤                                   |
| 4    | 发布推理服务            | 将模型发布为在线推理服务                                                                        |                                                                                           |
| 5    | 调用推理服务            | 通过 API 或“体验”功能调用推理服务                                                               |                                                                                           |

## 操作步骤

### 操作步骤 1: 创建命名空间并分配用户权限

**注意：如果您已经有命名空间且已分配用户权限，请跳过此步骤**

命名空间是 Alauda AI 多租户隔离的基础，每个项目应使用独立的命名空间。

1. 以管理员身份登录容器平台。
2. 进入 **项目管理**，选择或创建一个项目。
3. 在项目详情页，点击 **命名空间**。
4. 点击 **创建命名空间**，输入一个名称（例如：“text-classification-demo”）。
5. 点击 **创建** 完成命名空间创建。
6. 为用户分配命名空间权限：
   - 进入 **管理员** > **用户** > **用户**。
   - 创建一个用户或选择一个需要使用该命名空间的现有用户。
   - 点击 **配置角色** > **添加角色**。
   - 添加 **Alauda AI 角色**，并将其与所创建的命名空间及其所属的项目关联。
     - aml-namespace-editor：供命名空间开发者使用，具有创建、删除、修改和查询模型及推理服务的权限。
     - aml-namespace-owner：供命名空间管理者使用。
     - aml-namespace-viewer：仅能查看模型、推理服务和其他资源。

### 操作步骤 2: 管理命名空间

**注意：如果命名空间已经被管理，请跳过此步骤**

将创建的命名空间纳入 Alauda AI 管理：

1. 进入 Alauda AI，选择顶部导航中的 **管理员**，在 **管理员** 右侧的“集群”中选择新创建命名空间所在的集群。
2. 在左侧导航栏中点击 **命名空间管理**，点击 **管理命名空间** 按钮。
3. 在弹出对话框中选择新创建的 “text-classification-demo” 命名空间。
4. 点击 **管理** 完成管理操作。

### 操作步骤 3: 上传模型

**注意：如果您已经上传了模型或使用的是平台共享模型，请跳过此步骤**

将文本分类模型上传到模型库：

1. 进入 Alauda AI，选择顶部导航中的 **业务视图**，并选择之前步骤中管理的命名空间。
2. 在左侧导航栏中点击 **模型库**，点击 **创建模型库**，输入准备好的模型名称，例如 “gpt2”。
3. 创建后，进入模型详情页上的 **文件管理** 标签。
4. 点击 **导入模型文件**，拖动或选择模型文件/子文件夹进行上传。如果上传大型语言模型，由于文件较大，界面可能会冻结，建议使用 git push 命令将大型模型文件推送到模型库。
5. 点击 **导入** 按钮，并等待上传完成。
6. 在 **文件管理** 标签中，点击 **更新元数据**，根据大模型的属性选择正确的“任务类型”和“框架”。
   - 任务类型：是模型自身的属性，可以通过查看模型下载详情页上的标签获得，分为“文本生成”、“图像生成”等。
   - 框架：也是模型自身的属性，可以通过查看模型下载详情页上的标签获得，分为“Transformers”、“MLflow”等。大多数流行的开源大型语言模型为“Transformers”类型。

### 操作步骤 4: 发布推理服务

将模型发布为在线推理服务：

1. 在模型详情页上，点击 **发布推理 API** > **自定义发布**。
2. 配置服务参数：
   - 名称：gpt2-service
   - 模型：gpt2
   - 版本：Branch-main
   - 推理运行时：需要根据 GPU 节点中安装的 cuda 版本进行选择。例如，如果安装了 cuda11 驱动，选择“vllm-cuda11.8-x86”；如安装了 cuda12，选择“vllm-cuda12.1-x86”。
   - 资源请求：1CPU/4Gi 内存
   - 资源限制：2CPU/6Gi 内存
   - GPU 加速：GPU 管理器
     - GPU vcore：30
     - GPU vmemory：32
   - 存储：挂载现有 PVC/创建 PVC 或临时存储/容量 10Gi
   - 自动伸缩：关闭
   - 实例数：1
3. 点击 **发布** 并等待服务启动。
4. 在 **推理服务** 页面查看服务状态。

### 操作步骤 5: 调用推理服务

测试发布的推理服务：

1. 点击左侧导航栏中的 **推理服务**，点击“发布的推理服务”的名称，然后在推理服务详情页上点击 **体验**。
2. 输入测试文本，例如“推荐几本好书”。
3. 查看模型返回的生成文本和生成参数。
