---
weight: 40
i18n:
  title:
    en: Release Notes
sourceSHA: ee712efe3d67609d2cb075d890a59fc25629b3b57187e9f1fa4fbf0e68c539c4
---

# 发版说明

## AI 1.3.0

### 新增及优化功能

#### 共享模型权限限制

当前模型库支持两种模型类型：**共享模型**和**私有模型**。在最初的设计中，用户可以对共享模型执行某些管理操作，可能存在权限风险。\
在此版本中，私有模型的功能和权限保持不变，支持完全的管理操作。**共享模型的权限进行了限制和优化**，具体如下：

- 权限限制：所有用户可以使用共享模型，创建、编辑或删除共享模型的能力不再支持。
- 创建流程调整：在“创建模型”流程中，去掉了可见性参数。所有新创建的模型默认为**私有模型**。
- 功能移除：
  - 对于共享模型，以下功能被移除：
    - 编辑标签按钮
    - 编辑描述按钮
    - 创建标签按钮
    - 删除按钮
    - 文件管理标签
    - 版本管理标签

#### 推理服务的新模板发布功能

之前，创建推理服务需要手动配置许多相互依赖的参数。这种复杂性常常导致错误，降低成功率，并影响用户体验。\
在此版本中，引入了**模板发布**能力，用户可以将经过验证的配置封装为模板，并快速基于这些模板发布推理服务。\
其好处包括：

- 用户可以创建自定义模板，重用经过验证的最佳实践。
- 参数配置的自动填充减少了重复输入和依赖错误。
- 降低了发布大型模型推理服务的门槛，提高了成功率和效率。

#### 单节点上的多GPU支持推理运行时

之前，部署在单节点上的推理服务仅支持**单GPU**模式，由于资源调度限制。这限制了大型模型推理场景并未充分利用GPU资源。\
随着此次升级，现支持**单节点内的多GPU调度**。单个推理服务可以在同一台机器上自动分配多个GPU，从而支持更大模型的推理，更好地利用资源，并增强服务能力。

#### 推理服务的“业务监控”

之前的推理服务仅显示基本信息。为了增强可观察性，使用户能够快速检测问题、实时监测服务健康状况并主动优化或调整资源，推出以下新功能：\
**监控仪表盘**

- 新增为推理服务中的一个选项卡，涵盖三个维度：
  - **资源监控**：CPU使用量（核心数）、CPU利用率（%）、内存使用量（GiB）、内存利用率（%）
  - **计算监控**：GPU使用量（核心数）、GPU利用率（%）、GPU内存使用量（GiB）、GPU内存利用率（%）
  - **其他指标**：响应时间、流量（进出数据量）、QPS（每秒查询数）、总调用数、令牌吞吐量（/s）

#### 推理运行时扩展

为增强AML推理运行时支持，在此版本中新增以下运行时：

- vllm-cuda-11.8
- vllm-cpu

#### 专用“平台管理视图”

之前，平台管理功能（包括命名空间管理和凭证管理）混合于一个视图中，因权限级别混杂而导致的混淆。\
在此版本中：

- **平台管理功能被分离到一个独立视图中**，仅**管理员可见和操作**。
- 管理员可以通过顶部导航在**“管理视图”**和**“业务视图”**之间自由切换。
- 普通用户只能访问**业务视图**，无法访问平台管理功能。

#### 命名空间引导自动配置GitLab Token

之前，在引导一个命名空间时，用户必须手动配置GitLab Token以授权对仓库的访问。\
此次版本通过实现**自动GitLab Token配置**优化了GitLab授权流程：

- 对于每个新引导的命名空间，平台会自动配置GitLab Token。
- 用户无需手动操作或管理GitLab授权。
- 确保所有管理命名空间持续访问GitLab。

### 下线功能

#### α特性的降级至S2阶段

在AML平台迭代过程中，一些模块作为**α特性**发布，以探索验证设计和用户需求。\
然而，由于大型模型开发场景快速变化以及用户需求的演变，一些α特性存在设计缺陷或适用性有限。这些特性将进行**重新评估**，并**降级至S2阶段**以作未来规划。\
以下特性被降级：

- **数据集**：数据集库、数据标注
- **模型优化**：任务模板、模型微调、预训练
- **代理**：应用库、Dify
- **高级功能**：笔记本、存储卷、MLFlow、Tensorboard、工作流、工作流任务、定时任务、AutoML
- **模型**：构建推理API镜像

### 修复问题

{/* release-notes-for-bugs */}

### 已知问题

{/* release-notes-for-bugs */}
