---
weight: 10
sourceSHA: f438f0c1baffd7737aeedebb26ecba00d2da0443662146851f9230ccc82f175b
---

# 介绍

推理服务是 Alauda AI 平台的核心功能，专注于高效部署 LLM 模型作为在线推理服务，支持 HTTP API 和 gRPC 等多种调用方式。通过推理服务，用户可以快速构建 LLM 应用程序，并向外提供稳定、高性能的 LLM 能力。

<Directive type="warning">
  在容器中运行内置运行时需要根权限。请确保在可信环境中使用，并遵循安全策略。
</Directive>

## 核心优势

- **快速模型部署：**
  - 支持从模型库直接部署推理服务，简化部署步骤。
  - 支持用户定义的 Docker 镜像，以部署复杂的用户定义推理服务。
- **多框架运行时支持：**
  - 集成主流推理运行时，如 Seldon MLServer 和 vLLM，支持多种模型框架，满足不同模型的部署需求。
- **可视化推理演示：**
  - 为常见任务类型提供可视化“推理演示”功能，便于用户快速验证推理结果。
- **灵活的调用方式：**
  - 支持 HTTP API 和 gRPC 等多种调用方式，允许用户在不同应用场景下调用 LLM 能力。

## 应用场景

- **在线 LLM 应用：**
  - 将 LLM 模型部署为在线服务，以向外提供 LLM 能力。
- **实时推理：**
  - 支持实时推理场景，满足对响应速度要求高的应用需求。
- **批量推理：**
  - 支持批量推理，对大规模数据集执行推理计算。
- **应用集成：**
  - 通过 API 将 LLM 能力集成到现有应用中。
