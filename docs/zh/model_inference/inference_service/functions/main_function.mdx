---
weight: 10
sourceSHA: a93f1b24935100b96ac2659af9a5379d619c98d6f062d0513b12c48a0a63d62c
---

# 功能介绍

推断服务功能的核心定义是将训练好的机器学习或深度学习模型部署为可在线调用的服务，使用 HTTP API 或 gRPC 等协议，使应用程序能够实时或批量使用模型的预测、分类、生成等特性。该功能主要解决模型训练完成后如何高效、稳定、便捷地将模型部署到生产环境中，并提供可扩展的在线服务。

## 优势

- 简化模型部署流程，降低部署复杂性。
- 提供高可用性、高性能的在线和批量推断服务。
- 支持动态模型更新和版本管理。
- 实现模型推断服务的自动化运维和监控。

## 适用场景

- 实时推荐系统：基于用户行为的实时商品或内容推荐。
- 图像识别：对上传图像进行分类、检测或识别。
- 自然语言处理：提供文本分类、情感分析和机器翻译等服务。
- 金融风险控制：实时评估用户信用风险或交易风险。
- 大语言模型服务：提供在线问答、文本生成等服务。
- 批量推断：对大量非实时数据进行推断，如历史数据分析和报告生成。

## 带来的价值

- 加快模型部署，缩短应用开发周期。
- 提高模型推断效率，降低延迟。
- 降低运维成本，提高系统稳定性。
- 支持快速业务迭代和创新。

## 主要特性

**直接模型部署推断服务**

- 允许用户从模型库中直接选择特定版本的模型文件，并指定推断运行时镜像，快速部署在线推断服务。系统自动下载、缓存并加载模型，启动推断服务。这简化了模型部署流程，降低了部署门槛。

**自定义镜像部署推断服务**

- 支持用户编写 Dockerfile 将模型及其依赖打包为自定义镜像，然后通过标准 Kubernetes 部署推断服务。这种方法提供了更大的灵活性，允许用户根据需求自定义推断环境。

**推断服务的批量操作**

- 支持对多个推断服务进行批量操作，如批量启动、停止、更新和删除。
- 能够支持批量推断任务的创建、监控和结果导出。
- 提供批量资源管理，可以对推断服务进行批量资源分配和调整。

**推断服务体验**

- 提供交互式界面，方便用户测试和体验推断服务。
- 支持多种输入输出格式，以满足不同应用场景的需求。
- 提供模型性能评估工具，帮助用户优化模型部署。

**推断运行时支持**

- 集成多种主流推断框架，如 vLLM、Seldon MLServer 等，并支持用户自定义推断运行时。

:::tip

- vLLM：针对像 DeepSeek/Qwen 等大型语言模型进行了优化，具备高并发处理和增强的吞吐量，资源效率更高。
- MLServer：专为传统 ML 模型（如 XGBoost/图像分类）设计，提供多框架兼容性和简化的调试功能。

:::

**接入方式、日志、Swagger、监控等**

- 提供多种接入方式，如 HTTP API 和 gRPC。
- 支持详细日志记录和分析，方便用户排查故障。
- 自动生成 Swagger 文档，以方便用户集成及调用推断服务。
- 提供实时监控和报警功能，以确保服务稳定运行。

# 功能优势

**性能优势：**

- 支持 GPU 加速，提高模型推断速度。
- 支持批量推断，提高吞吐量。
- 优化推断运行时，降低延迟。

**可扩展性：**

- 基于 Kubernetes 搭建，支持弹性伸缩。
- 支持水平扩展以应对高并发场景。
- 支持大模型的分布式推断。
- 支持批量任务的并行处理。

**安全性：**

- 提供身份验证和授权机制，以确保服务安全。
- 支持网络隔离，防止数据泄露。
- 支持安全部署和更新模型。

**稳定性：**

- 提供健康检查和自动重启机制，提高服务可用性。
- 支持日志监控和报警，及时发现和解决问题。

## 创建推断服务

<Steps>
  ### 步骤 1

  **选择自定义发布**

  :::tip
  自定义发布推断服务需要手动设置参数。您也可以通过组合输入参数来创建“模板”，以快速发布推断服务。
  :::

  ### 步骤 2

  **提供推断服务的模型发布详情**

  | 参数                   | 描述                                                                                                                |
  | :--------------------- | :----------------------------------------------------------------------------------------------------------------- |
  | 名称                   | 必填，推断 API 的名称。                                                                                            |
  | 描述                   | 推断 API 的详细描述，解释其功能和目的。                                                                            |
  | 模型                   | 必填，用于推断的模型名称。                                                                                        |
  | 版本                   | 必填，模型的版本。选项包括 Branch 和 Tag。                                                                        |
  | 推断运行时             | 必填，用于推断的运行时引擎。                                                                                      |
  | 请求 CPU               | 必填，推断服务所请求的 CPU 资源量。                                                                              |
  | 请求内存               | 必填，推断服务所请求的内存资源量。                                                                              |
  | 限制 CPU               | 必填，推断服务可使用的最大 CPU 资源量。                                                                          |
  | 限制内存               | 必填，推断服务可使用的最大内存资源量。                                                                          |
  | GPU 加速类型           | GPU 加速的类型。                                                                                                |
  | GPU 加速值             | GPU 加速的值。                                                                                                  |
  | 临时存储               | 推断服务使用的临时存储空间。                                                                                    |
  | 挂载现有 PVC           | 将现有的 Kubernetes 持久卷声明 (PVC) 挂载为存储。                                                                |
  | 容量                   | 必填，临时存储或 PVC 的容量大小。                                                                                |
  | 自动伸缩               | 启用或禁用自动伸缩功能。                                                                                        |
  | 实例数量               | 必填，运行推断服务的实例数量。                                                                                  |
  | 环境变量               | 注入到容器运行时环境的键值对。                                                                                  |
  | 添加参数               | 传递给容器入口点可执行文件的参数。字符串数组（例如 \["--port=8080", "--batch\_size=4"]）。                      |
  | 启动命令               | 覆盖容器镜像中的默认 ENTRYPOINT 指令。可执行文件 + 参数（例如 \["python", "serve.py"]）。                       |

  ### 步骤 3

  点击 **发布** 按钮以创建推断服务。
</Steps>

## 体验

<Steps>
  ### 步骤 1

  在 **推断 API** 服务列表中，点击任何 **运行中** 服务的名称以查看其详细信息。

  ### 步骤 2

  点击 **体验** 以展开右侧面板。

  ### 步骤 3

  提问

  - 系统角色

    定义 AI 的目的、语调和操作边界（例如，“你是一个专门提供医疗信息的有用助手”）。

  - 参数

    根据您的任务类型选择参数。有关详细信息，请参考下面的参数描述。
</Steps>

**不同任务类型的参数描述**

**文本生成**

*预设参数*

| 参数                 | 数据类型 | 描述                                                                                                                     |
| -------------------- | --------- | ----------------------------------------------------------------------------------------------------------------------- |
| `do_sample`          | bool      | 是否使用采样；如果不使用，采用贪心解码。                                                                                |
| `max_new_tokens`     | int       | 最大生成的标记数，忽略提示中的标记。                                                                                  |
| `repetition_penalty` | float     | 控制生成文本中重复内容的重复惩罚；1.0 表示没有重复，0 表示重复。                                                      |
| `temperature`        | float     | 生成文本时模型对下一个标记的随机性；1.0 表示高随机性，0 表示低随机性。                                              |
| `top_k`              | int       | 在计算下一个标记的概率分布时，仅考虑具有最高概率的前 k 个标记。                                                       |
| `top_p`              | float     | 控制模型选择下一个标记时考虑的累积概率分布。                                                                          |
| `use_cache`          | bool      | 是否使用模型在生成过程中的中间结果。                                                                                 |

*其他参数*

| 参数                 | 数据类型 | 描述                                                                                                                                                                                                                                                                    |
| -------------------- | --------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `max_length`         | int       | 最大生成的标记数量。对应输入提示中的标记数量 + `max_new_tokens`。如果设置了 `max_new_tokens`，则其效果会覆盖 `max_length`。                                                                                                                                   |
| `min_length`         | int       | 最小生成的标记数量。对应输入提示中的标记数量 + `min_new_tokens`。如果设置了 `min_new_tokens`，则其效果会覆盖 `min_length`。                                                                                                                                   |
| `min_new_tokens`     | int       | 最小生成的标记数量，忽略提示中的标记。                                                                                                                                                                                                                               |
| `early_stop`         | bool      | 控制基于束搜索的方法的停止条件。True：生成在出现 `num_beams` 个完整候选时停止。False：应用启发式方法，当不太可能找到更好的候选时停止生成。                                                                                                         |
| `num_beams`          | int       | 用于束搜索的束数。1 表示不使用束搜索。                                                                                                                                                                                                                                 |
| `max_time`           | int       | 计算的最大运行时间，以秒为单位。                                                                                                                                                                                                                                       |
| `num_beam_groups`    | int       | 将 `num_beams` 分为多个组，以确保不同束组之间的多样性。                                                                                                                                                                                                            |
| `diversity_penalty`  | float     | 当启用 `num_beam_groups` 时有效。该参数在组之间应用多样性惩罚，以确保每组生成的内容尽可能不同。                                                                                                                                                                         |
| `penalty_alpha`      | float     | 当 `penalty_alpha` 大于 0 且 `top_k` 大于 1 时启用对比搜索。`penalty_alpha` 值越大，对比惩罚越强，生成的文本越有可能符合预期。如果值设置得过大，可能会导致生成的文本过于单一。                                                                                        |
| `typical_p`          | float     | 局部典型性度量预测下一个目标标记的条件概率与给定已生成部分文本的下一个随机标记的期望条件概率之间的相似度。如果设置为小于 1 的浮点数，则将保留与 `typical_p` 相加或超过的局部典型标记的最小集合用于生成。                                               |
| `epsilon_cutoff`     | float     | 如果设置为严格在 0 和 1 之间的浮点数，则仅采样条件概率大于 `epsilon_cutoff` 的标记。建议值范围为 3e-4 至 9e-4，具体取决于模型的大小。                                                                                                                                                   |
| `eta_cutoff`         | float     | Eta 采样是局部典型采样和 epsilon 采样的混合。如果设置为严格在 0 和 1 之间的浮点数，则仅考虑条件概率大于 `eta_cutoff` 或 sqrt(`eta_cutoff`) \* exp(-entropy(softmax(next\_token\_logits))) 的标记。建议值范围为 3e-4 至 2e-3，具体取决于模型的大小。 |
| `repetition_penalty` | float     | 重复惩罚的参数。1.0 表示没有惩罚。                                                                                                                                                                                                                                                                         |

有关更多参数，请参阅 [文本生成参数配置](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation#transformers.GenerationConfig)。

**文本到图像**

*预设参数*

| 参数                   | 数据类型 | 描述                                                                                                                                                             |
| ---------------------- | --------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `num_inference_steps`  | int       | 去噪步骤的数量。更多的去噪步骤通常会导致更高质量的图像，但推断速度较慢。                                                                                       |
| `use_cache`            | bool      | 是否使用模型在生成过程中的中间结果。                                                                                                                           |

*其他参数*

| 参数             | 数据类型          | 描述                                                                                                                                                   |
| ----------------- | ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `height`          | int               | 生成图像的高度，以像素为单位。                                                                                                                           |
| `width`           | int               | 生成图像的宽度，以像素为单位。                                                                                                                           |
| `guidance_scale`  | float             | 用于调整生成图像的质量与多样性之间的平衡。较大的值会增加多样性，但降低质量；建议范围为 7 到 8.5。                                                      |
| `negative_prompt` | str 或 List\[str] | 用于指导在图像生成中不应包含的内容。                                                                                                                       |

有关更多参数，请参阅 [文本到图像参数配置](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)。

**文本分类**

*预设参数*

| 参数           | 数据类型 | 描述                                                                                                                                        |
| --------------- | --------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| `top_k`        | int       | 顶尖得分类型标签的数量。如果提供的数字为 None 或超过模型配置中可用标签的数量，则默认返回标签的数量。                                 |
| `use_cache`    | bool      | 是否使用模型在生成过程中的中间结果。                                                                                                   |

有关更多参数，请参阅 [文本分类参数配置](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/pipelines#transformers.TextClassificationPipeline.__call__)

##### 附加参考

[图像分类参数配置](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/pipelines#transformers.ImageClassificationPipeline.__call__)

[对话参数配置](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/pipelines#transformers.ConversationalPipeline.__call__)

[摘要参数配置](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/pipelines#transformers.SummarizationPipeline.__call__)

[翻译参数配置](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/pipelines#transformers.TranslationPipeline.__call__)

[文本到文本生成参数配置](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/pipelines#transformers.Text2TextGenerationPipeline.__call__)

[图像到图像参数配置](https://huggingface.co/docs/transformers/v4.36.1/en/main_classes/pipelines#transformers.ImageToImagePipeline.__call__)
